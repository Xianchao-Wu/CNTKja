{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "# CNTK 200: A Guided Tour\n",
     "\n",
     "This tutorial exposes many advanced features of CNTK and is aimed towards people who have had some previous exposure to deep learning and/or other deep learning toolkits. If you are a complete beginner we suggest you start with the CNTK 101 Tutorial and come here after you have covered most of the 100 series.\n",
     "\n",
     "Welcome to CNTK! Deep neural networks are redefining how computer programs are created. In addition to imperative, functional, declarative programming, we now have differentiable programming which effectively 'learns' programs from data.\n",
     "\n",
     "CNTK is the prime tool that Microsoft product groups use to create deep models for a whole range of products,\n",
     "from speech recognition and machine translation via various image-classification services\n",
     "to Bing search ranking.\n",
     "\n",
     "This tutorial is a guided tour of CNTK. It is primarily meant for users that are new to CNTK but have some experience with deep neural networks.\n",
     "The focus will be on how the basic steps of deep learning are done in CNTK,\n",
     "which we will show predominantly by example.\n",
     "This tour is not a complete API description. Instead, we refer the reader to the documentation\n",
     "and task-specific tutorials for more detailed information.\n",
     "\n",
     "To train a deep model, you will need to define your model structure, prepare your data so that it can be fed to CNTK, train the model and evaluate its accuracy, and deploy it.\n",
     "\n",
     "This guided tour is organized as follows:\n",
     "\n",
     " * Defining your **model structure**\n",
     "    * The CNTK programming model: Networks as Function Objects\n",
     "    * CNTK's Data Model: Tensors and Sequences of Tensors\n",
     "    * Your First CNTK Network: Logistic Regression\n",
     "    * Your second CNTK Network: MNIST Digit Recognition\n",
     "    * The Graph API: MNIST Digit Recognition Once More\n",
     " * Feeding your **data**\n",
     "    * Small data sets that fit into memory: numpy/scipy arrays/\n",
     "    * Large data sets: `MinibatchSource` class\n",
     "    * Spoon-feeding data: your own minibatch loop\n",
     " * **Training**\n",
     "    * Distributed Training\n",
     "    * Logging\n",
     "    * Checkpointing\n",
     "    * Cross-validation based training control\n",
     "    * Final evaluation\n",
     " * **Deploying** the model\n",
     "    * From Python\n",
     "    * From C++ and C#\n",
     "    * From your own web service\n",
     "    * Via an Azure web service\n",
     " * Conclusion\n",
     "\n",
     "To run this tutorial, you will need CNTK v2 and ideally a CUDA-capable GPU (deep learning is no fun without GPUs).\n",
     "\n",
     "We start with some imports we will use in the rest of the tutorial."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "# CNTK 200: 导游\n",
    "\n",
    "本教程公开了 CNTK 的许多高级功能, 并面向那些以前接触过深入学习和/或其他深层学习工具包的人。如果你是一个完整的初学者, 我们建议你开始与 CNTK 101 教程, 来到这里后, 你已经涵盖了大部分的100系列。\n",
    "\n",
    "欢迎来到 CNTK!深层神经网络正在重新定义计算机程序的创建方式。除了必需的、功能性的、声明式编程之外, 我们现在还有可微编程, 有效地从数据中 \"学习\" 程序。\n",
    "\n",
    "CNTK 是 Microsoft 产品组用来为整个产品系列创建深度模型的主要工具, 从语音识别和机器翻译到通过各种图像分类服务到 Bing 搜索排名。\n",
    "\n",
    "本教程是导游 CNTK。它的主要目的是为用户是新的 CNTK, 但有一定的经验, 深神经网络。\n",
    "重点将是如何在 CNTK 的基本步骤进行深入的学习, 我们将主要以实例显示。\n",
    "此教程不是完整的 API 描述。相反, 我们将读者参考文档和特定于任务的教程, 以获取更详细的信息。\n",
    "\n",
    "为了训练一个深模型, 你需要定义你的模型结构, 准备你的数据, 以便它可以被 CNTK, 训练模型并评估它的准确性, 并进行部署。\n",
    "\n",
    "这次导游安排如下:\n",
    "\n",
    "- 定义**模型结构**\n",
    "\n",
    "- CNTK 编程模型: 网络作为功能对象\n",
    "\n",
    "- CNTK 的数据模型: 张量和张张序列\n",
    "\n",
    "- 您的第一个 CNTK 网络: 逻辑回归\n",
    "\n",
    "- 您的第二个 CNTK 网络: MNIST 数字识别\n",
    "\n",
    "- 图形 API: MNIST 数字识别\n",
    "\n",
    "- 喂养**数据**\n",
    "\n",
    "- 适合内存的小型数据集: numpy/scipy 阵列/\n",
    "\n",
    "- 大型数据集: `MinibatchSource` 类\n",
    "\n",
    "- 勺子喂养数据: 您自己的 minibatch 循环\n",
    "\n",
    "- **培训**\n",
    "\n",
    "- 分布式培训\n",
    "\n",
    "- 记录\n",
    "\n",
    "- 检查\n",
    "\n",
    "- 基于交叉验证的培训控制\n",
    "\n",
    "- 最终评估\n",
    "\n",
    "- **部署**模型\n",
    "\n",
    "- 从 Python\n",
    "\n",
    "- 从 c++ 和 c#\n",
    "\n",
    "- 从您自己的 web 服务\n",
    "\n",
    "- 通过 Azure web 服务\n",
    "\n",
    "- 结论\n",
    "\n",
    "要运行本教程, 您将需要 CNTK v2 和理想的 CUDA 的 GPU (深入学习是没有 gpu 的乐趣)。\n",
    "\n",
    "我们从一些导入, 我们将使用在其余的教程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cntk\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import cntk.tests.test_utils\n",
    "cntk.tests.test_utils.set_device_from_pytest_env() # (only needed for our build system)\n",
    "cntk.cntk_py.set_fixed_random_seed(1) # fix the random seed so that LR examples are repeatable\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot\n",
    "%matplotlib inline\n",
    "matplotlib.pyplot.rcParams['figure.figsize'] = (40,40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "original_source": [
     "## Defining Your Model Structure\n",
     "\n",
     "So let us dive right in. Below we will introduce CNTK's data model and CNTK's programming model--*networks are function objects*  (i.e. a network can be called like a function, and it also holds some state, the weights, or parameters, that get adjusted during learning). We will put that into action for logistic regression and MNIST digit recognition,\n",
     "using CNTK's Functional API. Lastly, CNTK also has a lower-level graph API. We will replicate one example with it.\n",
     "\n",
     "### The CNTK Programming Model: Networks are Function Objects\n",
     "\n",
     "In CNTK, a neural network is a function object.\n",
     "On one hand, a neural network in CNTK is just a function that you can call\n",
     "to apply it to data.\n",
     "On the other hand, a neural network contains learnable parameters\n",
     "that can be accessed like object members.\n",
     "Complicated networks can be composed as hierarchies of simpler ones, which,\n",
     "for example, represent layers.\n",
     "The function-object approach is similar to [Keras](https://keras.io), [Chainer](http://chainer.org), [Dynet](https://github.com/clab/dynet), [Pytorch](http://pytorch.org/), and [Sonnet](https://github.com/deepmind/sonnet).\n",
     "\n",
     "The following illustrates the function-object approach with **pseudo-code**, using the example\n",
     "of a fully-connected layer (called `Dense` in CNTK):"
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "## 定义模型结构\n",
    "\n",
    "让我们潜水吧下面我们将介绍 CNTK 的数据模型和 CNTK 的编程模型--*网络是函数对象*(即网络可以像函数一样调用, 并且它还拥有在学习过程中得到调整的某些状态、权重或参数)。我们将使用 CNTK 的功能 API 将其应用于逻辑回归和 MNIST 数字识别。最后, CNTK 还有一个较低级别的图形 API。我们将用它来复制一个例子。\n",
    "\n",
    "### CNTK 编程模型: 网络是功能对象\n",
    "\n",
    "在 CNTK 中, 神经网络是一个函数对象。\n",
    "一方面, CNTK 中的神经网络只是一个函数, 您可以调用它将其应用于数据。\n",
    "另一方面, 神经网络包含可以像对象成员一样访问的学习参数。\n",
    "复杂的网络可以组成简单的层次结构, 例如, 表示层。\n",
    "函数对象方法类似于[Keras](https://keras.io)、[链接](http://chainer.org)、 [Dynet](https://github.com/clab/dynet)、 [Pytorch](http://pytorch.org/)和[十四行诗](https://github.com/deepmind/sonnet)。\n",
    "\n",
    "下面用完全连接的层 (称为在 CNTK 中) 的例子说明了函数对象方法和**伪代码** `Dense` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [[-0.04255305 -0.00306212 -0.06292971 -0.00450488 -0.0248121 ]\n",
      " [-0.03296314  0.00635099 -0.1045115  -0.00292458  0.0368143 ]]\n",
      "y = [-0.1080558   0.00963955 -0.26544091 -0.01035366  0.04877776]\n"
     ]
    }
   ],
   "source": [
    "# *Conceptual* numpy implementation of CNTK's Dense layer (simplified, e.g. no back-prop)\n",
    "def Dense(out_dim, activation):\n",
    "    # create the learnable parameters\n",
    "    b = np.zeros(out_dim)\n",
    "    W = np.ndarray((0,out_dim)) # input dimension is unknown\n",
    "    # define the function itself\n",
    "    def dense(x):\n",
    "        if len(W) == 0: # first call: reshape and initialize W\n",
    "            W.resize((x.shape[-1], W.shape[-1]), refcheck=False)\n",
    "            W[:] = np.random.randn(*W.shape) * 0.05\n",
    "        return activation(x.dot(W) + b)\n",
    "    # return as function object: can be called & holds parameters as members\n",
    "    dense.W = W\n",
    "    dense.b = b\n",
    "    return dense\n",
    "\n",
    "d = Dense(5, np.tanh)    # create the function object\n",
    "y = d(np.array([1, 2]))  # apply it like a function\n",
    "W = d.W                  # access member like an object\n",
    "print('W =', d.W)\n",
    "print('y =', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "Again, this is only **pseudo-code**. In reality, CNTK function objects are not backed by numpy arrays.\n",
     "Rather, they are represented internally as graph structures in C++ that encode the computation, similar to other deep learning toolkits. In fact the line\n",
     "\n",
     "```python\n",
     "d = Dense(5, np.tanh)\n",
     "``` \n",
     "\n",
     "is just construsting a graph, while the line \n",
     "\n",
     "```python\n",
     "y = d(np.array([1, 2]))\n",
     "``` \n",
     "\n",
     "is feeding data to the graph execution engine.\n",
     "\n",
     "This graph structure is wrapped in the Python class `Function` that exposes the necessary interface so that other Python functions can call it and access its members (such as `W` and `b`).\n",
     "\n",
     "The function object is CNTK's single abstraction used to represent different operations, which\n",
     "are only distinguished by convention:\n",
     "\n",
     " * **basic operations** without learnable parameters (e.g. `+`, `*`, `sigmoid()`...)\n",
     " * **layers** (`Dense()`, `Embedding()`, `Convolution()`...). Layers map one input to one output and may have learnable parameters attached to them.\n",
     " * **recurrent step functions** (`LSTM()`, `GRU()`, `RNNStep()`). Step functions map a previous state and a new input to a new state.\n",
     " * **loss and metric** functions (`cross_entropy_with_softmax()`, `binary_cross_entropy()`, `squared_error()`, `classification_error()`...).\n",
     "   In CNTK, losses and metric are not particularly special, they are just functions. The only difference is that while a CNTK function can have one or multiple outputs, a loss and metric must have a single output. Note that a loss does not have to output a scalar value: If the output of a loss is not scalar, CNTK will automatically define the loss as the sum of the outputs. This behavior can be overriden by explicitly performing a reduction operation by yourself.   \n",
     " * **models**. Models are defined by the user. A model maps features to predictions or scores, and is what gets deployed in the end.\n",
     " * **criterion function**. The criterion function maps (features, labels) to a loss and optionally a metric.\n",
     "   The Trainer optimizes the loss by SGD, and logs the metric. The metric may be non-differentiable, but the loss must be differentiable.\n",
     "\n",
     "Higher-order layers compose objects into more complex ones, including:\n",
     "\n",
     " * layer **stacking** (`Sequential()`, `For()`)\n",
     " * **recurrence** (`Recurrence()`, `Fold()`, `UnfoldFrom()`, ...)\n",
     "\n",
     "Networks are commonly defined by using existing CNTK functions (such as\n",
     "specific types of neural-network layers)\n",
     "and composing them using `Sequential()`.\n",
     "In addition, users can write their own functions\n",
     "as arbitrary Python expressions, as long as those consist of CNTK operations\n",
     "over CNTK data types.\n",
     "Python expressions get converted into the internal representation by wrapping them in a call to\n",
     "`Function()`. Expressions can be written as multi-line functions through decorator syntax (`@Function`).\n",
     "\n",
     "Even if an operation cannot be expressed by combining CNTK's primitives, there are mechanisms\n",
     "for [extending CNTK](https://www.cntk.ai/pythondocs/extend.html) by writing your own \"layer\"\n",
     "in Python (or in C++). This is advanced functionality, that you shouldn't worry about now,\n",
     "but it's good to know about it in case you ever need it.\n",
     "\n",
     "Finally, CNTK function objects enable easy parameter sharing. If you call the same\n",
     "function object at multiple places, all invocations will naturally share the same learnable parameters.\n",
     "To avoid sharing parameters, you simply create two different function objects.\n",
     "\n",
     "In summary, the function object is CNTK's single abstraction for conveniently defining\n",
     "simple and complex models, parameter sharing, and training objectives.\n",
     "\n",
     "It is also possible to define CNTK networks directly in terms of its underlying graph operations, similar to many other toolkits. And you can freely *mix and match* between the two styles of defining your neural network. This is discussed further below.\n",
     "\n",
     "### CNTK's Data model: Sequences of Tensors\n",
     "\n",
     "CNTK can operate on two types of data:\n",
     "\n",
     " * **tensors** (that is, N-dimensional arrays), dense or sparse\n",
     " * **sequences** of tensors\n",
     "\n",
     "The distinction is that the shape of a tensor is static during operation,\n",
     "while the length of a sequence depends on data.\n",
     "In CNTK we use axes to mean the same thing as dimensions for numpy arrays, \n",
     "i.e. a tensor of shape (7,10,6) has three *axes*.\n",
     "Tensors have *static axes*, while a sequence has an additional *dynamic axis*.\n",
     "A dynamic axis, is therefore a variable length axis.\n",
     "\n",
     "Categorical data is represented as sparse one-hot tensors \n",
     "(i.e. having all elements 0 except a single 1 at the position of the category it encodes).\n",
     "This allows to write embeddings and loss functions in a unified fashion as matrix products.\n",
     "\n",
     "Printing a CNTK function will give you an output similar to the following format:\n",
     "\n",
     "*Operation*(Sequence[Tensor[*shape*]], *other arguments*) -> Tensor[*shape*]\n",
     "\n",
     "When the *Operation* is `Composite` the function is representing the whole graph underneath it and what's shown is just the last operation. This graph has a certain number of inputs that expect particular types of inputs. When you print a function you will note **the absence of a batch dimension**. CNTK hides batching from the user. We want users to think in tensors and sequences, and leave mini-batching to CNTK. Unlike other toolkits, CNTK can also automatically batch sequences with different lengths into one minibatch, and handles all necessary padding and packing. Workarounds like 'bucketing' are not needed. The reason we are separatring the dynamic axes (batch and sequence) from the static axes is because there are only very few operations that affect these axes. By default you want to do something to every example in the batch and every element of a sequence. Only few special operations (such as recurrence, or batch normalization), need to deal with these axes."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "同样, 这只是**伪代码**。实际上, CNTK 函数对象不受 numpy 数组的支持。\n",
    "相反, 它们在内部作为图形结构在 c++ 中表示, 它对计算进行编码, 类似于其他深层学习工具包。事实上, 线\n",
    "\n",
    "`python\n",
    "d = Dense(5, np.tanh)`\n",
    "\n",
    "只是 construsting 图, 而线\n",
    "\n",
    "`python\n",
    "y = d(np.array([1, 2]))`\n",
    "\n",
    "正在将数据送到图形执行引擎。\n",
    "\n",
    "此图结构被封装在 python 类 `Function` 中, 它公开必要的接口, 以便其他 python 函数可以调用它并访问其成员 (如 `W` 和 `b` )。\n",
    "\n",
    "函数对象是 CNTK 的单一抽象, 用于表示不同的操作, 它们仅由约定加以区分:\n",
    "\n",
    "- 没有学习参数的**基本操作**(例如 `+` 、 `*` 、 `sigmoid()` ...)\n",
    "\n",
    "- **图层**(`Dense()`, `Embedding()`, `Convolution()`...).图层将一个输入映射到一个输出, 并且可能有学习参数附加到它们。\n",
    "\n",
    "- **经常性步骤函数**(`LSTM()`, `GRU()`, `RNNStep()`).步骤函数将上一个状态和新输入映射到新状态。\n",
    "\n",
    "- **损耗和跃点数**函数 ( `cross_entropy_with_softmax()` 、 `binary_cross_entropy()` 、 `squared_error()` 、. `classification_error()` ..)。\n",
    "   在 CNTK, 损失和公制不是特别的, 它们只是功能。唯一的区别是, 虽然 CNTK 函数可以有一个或多个输出, 但损耗和跃点数必须具有单个输出。请注意, 损失不必输出标量值: 如果损失的输出不是标量, CNTK 将自动将损失定义为输出的总和。通过显式执行缩减操作, 可以重写此行为。\n",
    "\n",
    "- **模型**。模型由用户定义。模型将功能映射到预测或分数, 并将其部署到最后。\n",
    "\n",
    "- **条件函数**。标准作用映射 (特征, 标签) 到损失和可选择地一个跃点数。\n",
    "   培训师通过 SGD 优化损失, 并记录指标。该度量可以是非可微的, 但损失必须是可微分的。\n",
    "\n",
    "高阶层将对象组合成更复杂的层次, 包括:\n",
    "\n",
    "- 层**堆叠**( `Sequential()` , `For()` )\n",
    "\n",
    "- **重复周期**(`Recurrence()`, `Fold()`, `UnfoldFrom()`, ...)\n",
    "\n",
    "网络通常是通过使用现有的 CNTK 函数 (如特定类型的神经网络层) 来定义的, 并使用 `Sequential()` 进行组合。\n",
    "此外, 用户可以将自己的函数编写为任意的 Python 表达式, 只要这些功能由 CNTK 的操作组成 CNTK 数据类型。\n",
    "Python 表达式通过将它们包装在对 `Function()` 的调用中来转换为内部表示形式。可以通过修饰符语法 ( `@Function` ) 将表达式写成多行函数。\n",
    "\n",
    "即使无法通过组合 CNTK 的基元来表示操作, 也存在通过在 Python 中 (或在 c++ 中) 编写自己的 \"层\" 来[扩展 CNTK](https://www.cntk.ai/pythondocs/extend.html)的机制。这是先进的功能, 你不应该担心现在, 但它的好, 知道它的情况下, 你需要它。\n",
    "\n",
    "最后, CNTK 函数对象实现了简单的参数共享。如果在多个位置调用同一函数对象, 则所有调用都将自然共享相同的学习参数。\n",
    "为了避免共享参数, 您只需创建两个不同的函数对象即可。\n",
    "\n",
    "总之, 函数对象是 CNTK 的单一抽象, 用于方便地定义简单和复杂的模型、参数共享和培训目标。\n",
    "\n",
    "也可以直接根据其底层图形操作 (类似于许多其他工具包) 来定义 CNTK 网络。您可以在定义神经网络的两种风格之间自由地*混合和匹配*。下面将进一步讨论这一点。\n",
    "\n",
    "### CNTK 的数据模型: 张量序列\n",
    "\n",
    "CNTK 可以对两种类型的数据进行操作:\n",
    "\n",
    "- 张量**None**(即 N 维数组), 稠密或稀疏\n",
    "\n",
    "- 张量的**序列**\n",
    "\n",
    "区别是张量的形状在操作期间是静态的, 而序列的长度取决于数据。\n",
    "在 CNTK 中, 我们使用轴来表示与 numpy 数组的维度相同的东西, 即形状的张量 (7106) 有三*轴*。\n",
    "张量具有*静态轴*, 而序列有一个附加的*动态轴*。\n",
    "因此, 动态轴是可变长度轴。\n",
    "\n",
    "分类数据表示为稀疏的单热张量 (即, 除单个1之外的所有元素, 在它所编码的类别的位置上是 0)。\n",
    "这允许以统一的方式编写嵌入和损失函数作为矩阵产品。\n",
    "\n",
    "打印 CNTK 函数将为您提供类似于以下格式的输出:\n",
    "\n",
    "*操作*(序列 [张量 [*形状*],*其他参数*)-> 张量 [*形状*]\n",
    "\n",
    "当*操作*为 `Composite` 该函数表示它下面的整个关系图时, 所显示的只是最后一个操作。这个图有一定数量的输入, 期望特定类型的输入。在打印函数时, 您将注意到不**存在批处理维度**。CNTK 隐藏用户的批处理。我们希望用户在张量和序列的思考, 并留下迷你配料到 CNTK。与其他工具包不同, CNTK 还可以自动将不同长度的序列批处理为一个 minibatch, 并处理所有必要的填充和包装。不需要类似 \"桶\" 这样的变通方法。我们从静态轴 separatring 动态轴 (批处理和序列) 的原因是因为只有很少的操作会影响这些轴。默认情况下, 您希望对批处理中的每个示例和序列中的每个元素执行一些步骤。只有很少的特殊操作 (如重复或批处理正常化) 需要处理这些轴。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "### Your First CNTK Network: Simple Logistic Regression\n",
     "\n",
     "Let us put all of this in action for a very simple example of logistic regression.\n",
     "For this example, we create a synthetic data set of 2-dimensional normal-distributed \n",
     "data points, which should be classified into belonging to one of two classes.\n",
     "Note that CNTK expects the labels as one-hot encoded."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "### 您的第一个 CNTK 网络: 简单的逻辑回归\n",
    "\n",
    "让我们把这一切付诸行动, 为一个非常简单的例子, 逻辑回归。\n",
    "在这个例子中, 我们创建了一个2维正态分布数据点的综合数据集, 它应该被归类为属于两个类之一。\n",
    "请注意, CNTK 希望标签作为一个热编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data =\n",
      " [[ 2.2741797   3.56347561]\n",
      " [ 5.12873602  5.79089499]\n",
      " [ 1.3574543   5.5718112 ]\n",
      " [ 3.54340553  2.46254587]]\n",
      "labels =\n",
      " [[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "input_dim_lr = 2    # classify 2-dimensional data\n",
    "num_classes_lr = 2  # into one of two classes\n",
    "\n",
    "# This example uses synthetic data from normal distributions,\n",
    "# which we generate in the following.\n",
    "#  X_lr[corpus_size,input_dim] - input data\n",
    "#  Y_lr[corpus_size]           - labels (0 or 1), one-hot-encoded\n",
    "np.random.seed(0)\n",
    "def generate_synthetic_data(N):\n",
    "    Y = np.random.randint(size=N, low=0, high=num_classes_lr)  # labels\n",
    "    X = (np.random.randn(N, input_dim_lr)+3) * (Y[:,None]+1)   # data\n",
    "    # Our model expects float32 features, and cross-entropy\n",
    "    # expects one-hot encoded labels.\n",
    "    Y = scipy.sparse.csr_matrix((np.ones(N,np.float32), (range(N), Y)), shape=(N, num_classes_lr))\n",
    "    X = X.astype(np.float32)\n",
    "    return X, Y\n",
    "X_train_lr, Y_train_lr = generate_synthetic_data(20000)\n",
    "X_test_lr,  Y_test_lr  = generate_synthetic_data(1024)\n",
    "print('data =\\n', X_train_lr[:4])\n",
    "print('labels =\\n', Y_train_lr[:4].todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "We now define the model function. The model function maps input data to predictions.\n",
     "It is the final product of the training process.\n",
     "In this example, we use the simplest of all models: logistic regression."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "我们现在定义模型函数。模型函数将输入数据映射到预测。\n",
    "这是培训过程的最终成果。\n",
    "在这个例子中, 我们使用最简单的所有模型: 逻辑回归。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lr_factory = cntk.layers.Dense(num_classes_lr, activation=None)\n",
    "x = cntk.input_variable(input_dim_lr)\n",
    "y = cntk.input_variable(num_classes_lr, is_sparse=True)\n",
    "model_lr = model_lr_factory(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "Next, we define the criterion function. The criterion function is\n",
     "the harness via which the trainer uses to optimize the model:\n",
     "It maps (input vectors, labels) to (loss, metric).\n",
     "The loss is used for the SGD updates. We choose cross entropy.\n",
     "Specifically, `cross_entropy_with_softmax()` first applies\n",
     "the `softmax()` function to the network's output, as\n",
     "cross entropy expects probabilities.\n",
     "We do not include `softmax()` in the model function itself, because\n",
     "it is not necessary for using the model.\n",
     "As the metric, we count classification errors (this metric is not differentiable).\n",
     "\n",
     "We define criterion function as Python code and convert it to a `Function` object.\n",
     "A single expression can be written as `Function(lambda x, y: `*expression of x and y*`)`,\n",
     "similar to Keras' `Lambda()`.\n",
     "To avoid evaluating the model twice, we use a Python function definition\n",
     "with decorator syntax. This is also a good time to tell CNTK about the\n",
     "data types of our inputs, which is done via the decorator `@Function`:"
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "接下来, 我们定义了标准函数。标准函数是训练器用来优化模型的工具: 它映射 (输入向量、标签) 到 (损耗、跃点数)。\n",
    "该损失用于 SGD 更新。我们选择交叉熵。\n",
    "具体地说, `cross_entropy_with_softmax()` 首先将 `softmax()` 函数应用于网络的输出, 因为交叉熵预期概率。\n",
    "我们不在模型函数本身中包含 `softmax()` , 因为不需要使用模型。\n",
    "作为度量, 我们计算分类错误 (这个度量不是可微的)。\n",
    "\n",
    "我们将标准函数定义为 Python 代码, 并将其转换为 `Function` 对象。\n",
    "单个表达式可以写成 `Function(lambda x, y:` *x 和 y 的表达式* `)` , 类似于 Keras 的 `Lambda()` 。\n",
    "为了避免对模型进行两次评估, 我们使用了一个 Python 函数定义和修饰符语法。这也是一个好时机, 告诉 CNTK 我们输入的数据类型, 这是通过修饰 `@Function` 完成的:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion_lr: Composite(Tensor[2], SparseTensor[2]) -> Tuple[Tensor[1], Tensor[1]]\n"
     ]
    }
   ],
   "source": [
    "@cntk.Function\n",
    "def criterion_lr_factory(data, label_one_hot):\n",
    "    z = model_lr_factory(data)  # apply model. Computes a non-normalized log probability for every output class.\n",
    "    loss = cntk.cross_entropy_with_softmax(z, label_one_hot) # applies softmax to z under the hood\n",
    "    metric = cntk.classification_error(z, label_one_hot)\n",
    "    return loss, metric\n",
    "criterion_lr = criterion_lr_factory(x, y)\n",
    "print('criterion_lr:', criterion_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "The decorator will 'compile' the Python function into CNTK's internal graph representation.\n",
     "Thus, the resulting `criterion` not a Python function but a CNTK `Function` object.\n",
     "\n",
     "We are now ready to train our model."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "修饰者将 \"编译\" Python 函数到 CNTK 的内部图形表示中。\n",
    "因此, 结果 `criterion` 不是 Python 函数而是 CNTK `Function` 对象。\n",
    "\n",
    "我们现在已经准备好训练我们的模型了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate per minibatch: 0.1\n",
      "     3.58       3.58      0.562      0.562            32\n",
      "     1.61      0.629      0.458      0.406            96\n",
      "      1.1      0.715      0.464      0.469           224\n",
      "     0.88      0.688      0.454      0.445           480\n",
      "    0.734      0.598      0.427      0.402           992\n",
      "    0.637      0.543      0.351      0.277          2016\n",
      "    0.541      0.447      0.257      0.165          4064\n",
      "     0.45      0.359      0.186      0.115          8160\n",
      "    0.366      0.284      0.137     0.0876         16352\n",
      "[[-1.25055373 -0.53687984]\n",
      " [-0.99188507 -0.30086043]]\n"
     ]
    }
   ],
   "source": [
    "learner = cntk.sgd(model_lr.parameters,\n",
    "                   cntk.learning_parameter_schedule(0.1))\n",
    "progress_writer = cntk.logging.ProgressPrinter(0)\n",
    "\n",
    "criterion_lr.train((X_train_lr, Y_train_lr), parameter_learners=[learner],\n",
    "                   callbacks=[progress_writer])\n",
    "\n",
    "print(model_lr.W.value) # peek at updated W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "original_source": [
     "The `learner` is the object that actually performs the model update. Alternative learners include `momentum_sgd()` and `adam()`. The `progress_writer` is a stock logging callback that prints the output you see above, and can be replaced by your own\n",
     "or the stock `TensorBoardProgressWriter` to visualize training progress using TensorBoard.\n",
     "\n",
     "The `train()` function is feeding our data `(X_train_lr, Y_train_lr)` minibatch by minibatch to the model and updates it, where the data is a tuple in the same order as the arguments of `criterion_lr()`.\n",
     "\n",
     "Let us test how we are doing on our test set (this will also run minibatch by minibatch)."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "`learner`是实际执行模型更新的对象。替代学习者包括 `momentum_sgd()` 和 `adam()` 。`progress_writer`是一个股票记录回调, 用于打印您在上面看到的输出, 并可以由您自己或股票替换 `TensorBoardProgressWriter` , 以直观地显示使用 TensorBoard 的培训进度。\n",
    "\n",
    "`train()`函数正在向模型中 minibatch minibatch, 并将其更新, 其中数据是与 `criterion_lr()` 的参数顺序相同的元组。\n",
    "\n",
    "让我们测试一下我们是如何在我们的测试集 (这也将运行 minibatch 由 minibatch)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Evaluation [1]: Minibatch[1-32]: metric = 8.11% * 1024;\n"
     ]
    }
   ],
   "source": [
    "test_metric_lr = criterion_lr.test((X_test_lr, Y_test_lr),\n",
    "                                   callbacks=[progress_writer]).metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "original_source": [
     "And lastly, let us run a few samples through our model and see how it is doing.\n",
     "Oops, `criterion` knew the input types, but `model_lr` does not, so we tell it."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "最后, 让我们通过我们的模型运行一些样本, 看看它是如何做。\n",
    "哎呀, `criterion` 知道输入类型, 但 `model_lr` 没有, 所以我们告诉它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_lr: Dense(Tensor[2]) -> Tensor[2]\n"
     ]
    }
   ],
   "source": [
    "model_lr = model_lr_factory(x)\n",
    "print('model_lr:', model_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "Now we can call it like any Python function:"
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "现在我们可以像任何 Python 函数那样调用它:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label    : [0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1]\n",
      "Predicted: [0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "z = model_lr(X_test_lr[:20])\n",
    "print(\"Label    :\", [label.todense().argmax() for label in Y_test_lr[:20]])\n",
    "print(\"Predicted:\", [z[i,:].argmax() for i in range(len(z))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "### Your Second CNTK Network: MNIST Digit Recognition\n",
     "\n",
     "Let us do the same thing as above on an actual task--the MNIST benchmark, which is sort of the \"hello world\" of deep learning.\n",
     "The MNIST task is to recognize scans of hand-written digits. We first download and prepare the data.\n",
     "In Tutorial 103C you can find a more succinct way to write the entire MNIST digit recognition workflow using convenience functionality built into CNTK"
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "### 您的第二个 CNTK 网络: MNIST 数字识别\n",
    "\n",
    "让我们在实际任务上做同样的事情--MNIST 的基准, 这是一种深学习的 \"hello 世界\"。\n",
    "MNIST 的任务是识别手写数字的扫描。我们首先下载并准备数据。\n",
    "在教程103C 中, 您可以找到一种更简洁的方法, 使用内置 CNTK 的便利功能编写整个 MNIST 数字识别工作流"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAA+CAYAAABKr4xzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngiAkBZkaQRCS4v9FRqvLkHTWJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17217c4c240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_shape_mn = (28, 28)  # MNIST digits are 28 x 28\n",
    "num_classes_mn = 10        # classify as one of 10 digits\n",
    "\n",
    "# Fetch the MNIST data. Best done with scikit-learn.\n",
    "try:\n",
    "    from sklearn import datasets, utils\n",
    "    mnist = datasets.fetch_mldata(\"MNIST original\")\n",
    "    X, Y = mnist.data / 255.0, mnist.target\n",
    "    X_train_mn, X_test_mn = X[:60000].reshape((-1,28,28)), X[60000:].reshape((-1,28,28))\n",
    "    Y_train_mn, Y_test_mn = Y[:60000].astype(int), Y[60000:].astype(int)\n",
    "except: # workaround if scikit-learn is not present\n",
    "    import requests, io, gzip\n",
    "    X_train_mn, X_test_mn = (np.fromstring(gzip.GzipFile(fileobj=io.BytesIO(requests.get('http://yann.lecun.com/exdb/mnist/' + name + '-images-idx3-ubyte.gz').content)).read()[16:], dtype=np.uint8).reshape((-1,28,28)).astype(np.float32) / 255.0 for name in ('train', 't10k'))\n",
    "    Y_train_mn, Y_test_mn = (np.fromstring(gzip.GzipFile(fileobj=io.BytesIO(requests.get('http://yann.lecun.com/exdb/mnist/' + name + '-labels-idx1-ubyte.gz').content)).read()[8:], dtype=np.uint8).astype(int) for name in ('train', 't10k'))\n",
    "\n",
    "# Shuffle the training data.\n",
    "np.random.seed(0) # always use the same reordering, for reproducability\n",
    "idx = np.random.permutation(len(X_train_mn))\n",
    "X_train_mn, Y_train_mn = X_train_mn[idx], Y_train_mn[idx]\n",
    "\n",
    "# Further split off a cross-validation set\n",
    "X_train_mn, X_cv_mn = X_train_mn[:54000], X_train_mn[54000:]\n",
    "Y_train_mn, Y_cv_mn = Y_train_mn[:54000], Y_train_mn[54000:]\n",
    "\n",
    "# Our model expects float32 features, and cross-entropy expects one-hot encoded labels.\n",
    "Y_train_mn, Y_cv_mn, Y_test_mn = (scipy.sparse.csr_matrix((np.ones(len(Y),np.float32), (range(len(Y)), Y)), shape=(len(Y), 10)) for Y in (Y_train_mn, Y_cv_mn, Y_test_mn))\n",
    "X_train_mn, X_cv_mn, X_test_mn = (X.astype(np.float32) for X in (X_train_mn, X_cv_mn, X_test_mn))\n",
    "\n",
    "# Have a peek.\n",
    "matplotlib.pyplot.rcParams['figure.figsize'] = (5, 0.5)\n",
    "matplotlib.pyplot.axis('off')\n",
    "_ = matplotlib.pyplot.imshow(np.concatenate(X_train_mn[0:10], axis=1), cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "Let's define the CNTK model function to map (28x28)-dimensional images to a 10-dimensional score vector. We wrap that in a function so that later in this tutorial we can easily recreate it.\n",
     "For those familiar with Tutorial 103D, you will learn how to use the layers library to compose larger networks, train and test them in a simple way."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "让我们定义 CNTK 模型函数来映射 (28x28) 维图像到一个10维的分数向量。我们将其封装在一个函数中, 以便在本教程的后面部分可以轻松地重新创建它。\n",
    "对于那些熟悉教程103D 的人, 您将学习如何使用层库来组成更大的网络, 以简单的方式对它们进行培训和测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_mn_factory():\n",
    "    with cntk.layers.default_options(activation=cntk.ops.relu, pad=False):\n",
    "        return cntk.layers.Sequential([\n",
    "            cntk.layers.Convolution2D((5,5), num_filters=32, reduction_rank=0, pad=True), # reduction_rank=0 for B&W images\n",
    "            cntk.layers.MaxPooling((3,3), strides=(2,2)),\n",
    "            cntk.layers.Convolution2D((3,3), num_filters=48),\n",
    "            cntk.layers.MaxPooling((3,3), strides=(2,2)),\n",
    "            cntk.layers.Convolution2D((3,3), num_filters=64),\n",
    "            cntk.layers.Dense(96),\n",
    "            cntk.layers.Dropout(dropout_rate=0.5),\n",
    "            cntk.layers.Dense(num_classes_mn, activation=None) # no activation in final layer (softmax is done in criterion)\n",
    "        ])\n",
    "model_mn = create_model_mn_factory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "This model is a tad bit more complicated! It consists of several convolution-pooling layeres and two\n",
     "fully-connected layers for classification which is typical for MNIST. This demonstrates several aspects of CNTK's Functional API.\n",
     "\n",
     "First, we create each layer using a function from CNTK's layers library (`cntk.layers`).\n",
     "\n",
     "Second, the higher-order layer `Sequential()` creates a new function that applies all those layers\n",
     "one after another. This is known [forward function composition](https://en.wikipedia.org/wiki/Function_composition).\n",
     "Note that unlike some other toolkits, you cannot `Add()` more layers afterwards to a sequential layer.\n",
     "CNTK's `Function` objects are immutable, besides their learnable parameters (to edit a `Function` object, you can `clone()` it).\n",
     "If you prefer that style, create your layers as a Python list and pass that to `Sequential()`.\n",
     "\n",
     "Third, the context manager `default_options()` allows to specify defaults for various optional arguments to layers,\n",
     "such as that the activation function is always `relu`, unless overriden.\n",
     "\n",
     "Lastly, note that `relu` is passed as the actual function, not a string.\n",
     "Any function can be an activation function.\n",
     "It is also allowed to pass a Python lambda directly, for example relu could also be\n",
     "realized manually by saying `activation=lambda x: cntk.ops.element_max(x, 0)`.\n",
     "\n",
     "The criterion function is defined like in the previous example, to map maps (28x28)-dimensional features and according\n",
     "labels to loss and metric."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "这个模型稍微复杂一点!它由几个卷积池 layeres 和两个完全连通的层组成, 这是典型的 MNIST。这说明了 CNTK 的功能 API 的几个方面。\n",
    "\n",
    "首先, 我们使用 CNTK 的层库 ( `cntk.layers` ) 中的函数创建每个层。\n",
    "\n",
    "其次, 高阶层 `Sequential()` 创建一个新的函数, 它将所有这些层一个接一个地应用。这是已知的[正向函数组合](https://en.wikipedia.org/wiki/Function_composition)。\n",
    "请注意, 与其他一些工具包不同, 您不能 `Add()` 将更多的层之后用于顺序层。\n",
    "CNTK 的 `Function` 对象是不可变的, 除了它们的学习参数 (用于编辑 `Function` 对象外, 您可以 `clone()` 它)。\n",
    "如果您喜欢该样式, 请将您的图层创建为 Python 列表, 并将其传递给 `Sequential()` 。\n",
    "\n",
    "第三, 上下文管理器 `default_options()` 允许为层的各种可选参数指定默认值, 如激活函数总是 `relu` , 除非重写。\n",
    "\n",
    "最后, 请注意, `relu` 作为实际函数传递, 而不是字符串。\n",
    "任何函数都可以是激活函数。\n",
    "它还可以直接通过 Python lambda, 例如, relu 也可通过说 `activation=lambda x: cntk.ops.element_max(x, 0)` 来手动实现。\n",
    "\n",
    "标准函数的定义类似于前面的例子, 映射地图 (28x28) 维度特征, 并根据标签的损失和公制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@cntk.Function\n",
    "def criterion_mn_factory(data, label_one_hot):\n",
    "    z = model_mn(data)\n",
    "    loss = cntk.cross_entropy_with_softmax(z, label_one_hot)\n",
    "    metric = cntk.classification_error(z, label_one_hot)\n",
    "    return loss, metric\n",
    "x = cntk.input_variable(input_shape_mn)\n",
    "y = cntk.input_variable(num_classes_mn, is_sparse=True)\n",
    "criterion_mn = criterion_mn_factory(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "For the training, let us throw momentum into the mix."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "为训练, 让我们投掷动量入混合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(X_train_mn)\n",
    "lrs = cntk.learning_parameter_schedule_per_sample([0.001]*12 + [0.0005]*6 + [0.00025]*6 + [0.000125]*3 + [0.0000625]*3 + [0.00003125], epoch_size=N)\n",
    "momentums = cntk.momentum_schedule_per_sample([0]*5 + [0.9990239141819757], epoch_size=N)\n",
    "minibatch_sizes = cntk.minibatch_size_schedule([256]*6 + [512]*9 + [1024]*7 + [2048]*8 + [4096], epoch_size=N)\n",
    "\n",
    "learner = cntk.learners.momentum_sgd(model_mn.parameters, lrs, momentums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "This looks a bit unusual.\n",
     "First, the learning rate is specified as a list (`[0.001]*12 + [0.0005]*6 +`...). Together with the `epoch_size` parameter, this tells CNTK to use 0.001 for 12 epochs, and then continue with 0.005 for another 6, etc.\n",
     "\n",
     "Second, the learning rate is specified as if it is applied to a minibatch of size 1 (per-sample), \n",
     "and momentum as a time constant. These values specify directly the weight with which each sample's gradient\n",
     "contributes to the model, and how its contribution decays as training progresses. CNTK will scale the learning \n",
     "rate and momentum with respect to the real minibatch size of the data fed by the reader. The net effect of the scaling\n",
     "will make learning rate and momentum as if it is applied to a minibatch of size 1. This unique CNTK feature allows to adjust the minibatch size without retuning those parameters. Here, we grow it from 256 to 4096, leading to 3 times faster operation towards the end (on a Titan-X).\n",
     "\n",
     "Alright, let us now train the model. On a Titan-X, this will run for about a minute."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "这看起来有点不寻常。\n",
    "首先, 将学习速率指定为一个列表 ( `[0.001]*12 + [0.0005]*6 +` ...)。与 `epoch_size` 参数一起, 这告诉 CNTK 使用0.001 为12个世纪, 然后继续0.005 为另外 6, 等等。\n",
    "\n",
    "第二, 学习率被指定为, 如果它被应用到 minibatch 的大小 1 (每样), 和动量作为一个时间常数。这些值直接指定了每个样本的渐变对模型的贡献的权重, 以及它的贡献如何随着训练的进展而衰减。CNTK 将根据读者提供的数据的实际 minibatch 大小来扩展学习速度和动量。缩放的净效应将使学习速度和动量, 就像它被应用到大小1的 minibatch。此独特的 CNTK 功能允许在不调整这些参数的情况下调整 minibatch 的大小。在这里, 我们成长从256到 4096, 导致3倍的速度接近尾声 (在一个巨人 x) 的操作。\n",
    "\n",
    "好了, 现在让我们来训练这个模型。在一个泰坦 x, 这将运行大约一分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate per 1 samples: 0.001\n",
      "Momentum per 1 samples: 0.0\n",
      "Finished Epoch[1]: loss = 0.690009 * 54000, metric = 23.13% * 54000 376.212s (143.5 samples/s);\n",
      "Finished Epoch[2]: loss = 0.130801 * 54000, metric = 3.86% * 54000 374.211s (144.3 samples/s);\n",
      "Finished Epoch[3]: loss = 0.091346 * 54000, metric = 2.61% * 54000 377.380s (143.1 samples/s);\n",
      "Finished Epoch[4]: loss = 0.073643 * 54000, metric = 2.11% * 54000 373.727s (144.5 samples/s);\n",
      "Finished Epoch[5]: loss = 0.062448 * 54000, metric = 1.78% * 54000 377.726s (143.0 samples/s);\n",
      "Momentum per 1 samples: 0.9990239141819757\n",
      "Finished Epoch[6]: loss = 0.053981 * 54000, metric = 1.57% * 54000 382.536s (141.2 samples/s);\n",
      "Finished Epoch[7]: loss = 0.047834 * 54000, metric = 1.45% * 54000 362.123s (149.1 samples/s);\n",
      "Finished Epoch[8]: loss = 0.043945 * 54000, metric = 1.29% * 54000 366.161s (147.5 samples/s);\n",
      "Finished Epoch[9]: loss = 0.039856 * 54000, metric = 1.19% * 54000 359.380s (150.3 samples/s);\n",
      "Finished Epoch[10]: loss = 0.037814 * 54000, metric = 1.11% * 54000 359.232s (150.3 samples/s);\n",
      "Finished Epoch[11]: loss = 0.034455 * 54000, metric = 0.99% * 54000 355.878s (151.7 samples/s);\n",
      "Finished Epoch[12]: loss = 0.030696 * 54000, metric = 0.90% * 54000 350.948s (153.9 samples/s);\n",
      "Learning rate per 1 samples: 0.0005\n",
      "Finished Epoch[13]: loss = 0.023968 * 54000, metric = 0.74% * 54000 348.261s (155.1 samples/s);\n",
      "Finished Epoch[14]: loss = 0.021444 * 54000, metric = 0.65% * 54000 348.190s (155.1 samples/s);\n",
      "Finished Epoch[15]: loss = 0.020751 * 54000, metric = 0.60% * 54000 351.015s (153.8 samples/s);\n",
      "Finished Epoch[16]: loss = 0.021489 * 54000, metric = 0.66% * 54000 341.527s (158.1 samples/s);\n",
      "Finished Epoch[17]: loss = 0.018842 * 54000, metric = 0.57% * 54000 342.740s (157.6 samples/s);\n",
      "Finished Epoch[18]: loss = 0.019680 * 54000, metric = 0.61% * 54000 354.115s (152.5 samples/s);\n",
      "Learning rate per 1 samples: 0.00025\n",
      "Finished Epoch[19]: loss = 0.016658 * 54000, metric = 0.51% * 54000 360.945s (149.6 samples/s);\n",
      "Finished Epoch[20]: loss = 0.015646 * 54000, metric = 0.49% * 54000 359.710s (150.1 samples/s);\n",
      "Finished Epoch[21]: loss = 0.015150 * 54000, metric = 0.45% * 54000 364.494s (148.2 samples/s);\n",
      "Finished Epoch[22]: loss = 0.013552 * 54000, metric = 0.43% * 54000 360.311s (149.9 samples/s);\n",
      "Finished Epoch[23]: loss = 0.014498 * 54000, metric = 0.44% * 54000 355.536s (151.9 samples/s);\n",
      "Finished Epoch[24]: loss = 0.014109 * 54000, metric = 0.42% * 54000 350.968s (153.9 samples/s);\n",
      "Learning rate per 1 samples: 0.000125\n",
      "Finished Epoch[25]: loss = 0.013103 * 54000, metric = 0.38% * 54000 352.548s (153.2 samples/s);\n",
      "Finished Epoch[26]: loss = 0.012903 * 54000, metric = 0.38% * 54000 346.483s (155.9 samples/s);\n",
      "Finished Epoch[27]: loss = 0.011908 * 54000, metric = 0.37% * 54000 348.376s (155.0 samples/s);\n",
      "Learning rate per 1 samples: 6.25e-05\n",
      "Finished Epoch[28]: loss = 0.011621 * 54000, metric = 0.36% * 54000 351.408s (153.7 samples/s);\n",
      "Finished Epoch[29]: loss = 0.011913 * 54000, metric = 0.38% * 54000 344.531s (156.7 samples/s);\n",
      "Finished Epoch[30]: loss = 0.011110 * 54000, metric = 0.33% * 54000 348.696s (154.9 samples/s);\n",
      "Learning rate per 1 samples: 3.125e-05\n",
      "Finished Epoch[31]: loss = 0.010348 * 54000, metric = 0.30% * 54000 347.441s (155.4 samples/s);\n",
      "Finished Epoch[32]: loss = 0.011877 * 54000, metric = 0.39% * 54000 350.890s (153.9 samples/s);\n",
      "Finished Epoch[33]: loss = 0.011532 * 54000, metric = 0.36% * 54000 352.201s (153.3 samples/s);\n",
      "Finished Epoch[34]: loss = 0.011450 * 54000, metric = 0.36% * 54000 348.056s (155.1 samples/s);\n",
      "Finished Epoch[35]: loss = 0.011335 * 54000, metric = 0.36% * 54000 349.429s (154.5 samples/s);\n",
      "Finished Epoch[36]: loss = 0.011222 * 54000, metric = 0.35% * 54000 349.135s (154.7 samples/s);\n",
      "Finished Epoch[37]: loss = 0.011033 * 54000, metric = 0.34% * 54000 347.985s (155.2 samples/s);\n",
      "Finished Epoch[38]: loss = 0.011383 * 54000, metric = 0.34% * 54000 329.919s (163.7 samples/s);\n",
      "Finished Epoch[39]: loss = 0.010772 * 54000, metric = 0.32% * 54000 347.675s (155.3 samples/s);\n",
      "Finished Epoch[40]: loss = 0.010688 * 54000, metric = 0.32% * 54000 348.465s (155.0 samples/s);\n",
      "Finished Evaluation [1]: Minibatch[1-313]: metric = 0.60% * 10000;\n"
     ]
    }
   ],
   "source": [
    "progress_writer = cntk.logging.ProgressPrinter()\n",
    "criterion_mn.train((X_train_mn, Y_train_mn), minibatch_size=minibatch_sizes,\n",
    "                   max_epochs=40, parameter_learners=[learner], callbacks=[progress_writer])\n",
    "test_metric_mn = criterion_mn.test((X_test_mn, Y_test_mn), callbacks=[progress_writer]).metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "## Graph API Example: MNIST Digit Recognition Again\n",
     "\n",
     "CNTK also allows networks to be written by using a graph-level API. This API is more verbose but sometimes more flexible. The following defines the same model and criterion function as above, and will get the same result."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "## 图形 API 示例: 再次 MNIST 数字识别\n",
    "\n",
    "CNTK 还允许使用图形级 API 编写网络。此 API 更详细, 但有时更灵活。下面定义了与上面相同的模型和标准函数, 并且将得到相同的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion_mn: Composite(images: Tensor[28,28], labels: SparseTensor[10]) -> Tuple[Tensor[1], Tensor[1]]\n"
     ]
    }
   ],
   "source": [
    "images = cntk.input_variable(input_shape_mn, name='images')\n",
    "with cntk.layers.default_options(activation=cntk.ops.relu, pad=False):\n",
    "    r = cntk.layers.Convolution2D((5,5), num_filters=32, reduction_rank=0, pad=True)(images)\n",
    "    r = cntk.layers.MaxPooling((3,3), strides=(2,2))(r)\n",
    "    r = cntk.layers.Convolution2D((3,3), num_filters=48)(r)\n",
    "    r = cntk.layers.MaxPooling((3,3), strides=(2,2))(r)\n",
    "    r = cntk.layers.Convolution2D((3,3), num_filters=64)(r)\n",
    "    r = cntk.layers.Dense(96)(r)\n",
    "    r = cntk.layers.Dropout(dropout_rate=0.5)(r)\n",
    "    model_mn = cntk.layers.Dense(num_classes_mn, activation=None)(r)\n",
    "\n",
    "label_one_hot = cntk.input_variable(num_classes_mn, is_sparse=True, name='labels')\n",
    "loss = cntk.cross_entropy_with_softmax(model_mn, label_one_hot)\n",
    "metric = cntk.classification_error(model_mn, label_one_hot)\n",
    "criterion_mn = cntk.combine([loss, metric])\n",
    "print('criterion_mn:', criterion_mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "## Feeding Your Data\n",
     "\n",
     "Once you have decided your model structure and defined it, you are facing the question on feeding\n",
     "your training data to the CNTK training process.\n",
     "\n",
     "The above examples simply feed the data as numpy/scipy arrays.\n",
     "That is only one of three ways CNTK provides for feeding data to the trainer:\n",
     "\n",
     " 1. As **numpy arrays** or **scipy sparse (CSR) matrices**, for small data sets that can just be loaded into RAM.\n",
     " 2. Through instances of **CNTK's MinibatchSource class**, for large data sets that do not fit into RAM.\n",
     " 3. Through an **explicit minibatch-loop** when the above do not apply.\n",
     "\n",
     "### 1. Feeding Data Via Numpy/Scipy Arrays\n",
     "\n",
     "The `train()` and `test()` functions accept a tuple of numpy arrays or scipy sparse matrices (in CSR format) for their `minibatch_source` arguments.\n",
     "The tuple members must be in the same order as the arguments of the `criterion` function that `train()` or `test()` are called on.\n",
     "For dense tensors, use numpy arrays, while sparse data should have the type `scipy.sparse.csr_matrix`.\n",
     "\n",
     "Each of the arguments should be a Python list of numpy/scipy arrays, where each list entry represents a data item. For arguments declared as a sequence, the first axis (dimension) of the numpy/scipy array is the sequence length, while the remaining axes are the shape of each element of the sequence. Arguments that are not sequences consist of a single tensor. The shapes, data types (`np.float32/float64`) and sparseness must match the argument types.\n",
     "\n",
     "As an optimization, arguments that are not sequences can also be passed as a single large numpy/scipy array (instead of a list). This is what is done in the examples above.\n",
     "\n",
     "Note that it is the responsibility of the user to randomize the data.\n",
     "\n",
     "### 2. Feeding Data Using the `MinibatchSource` class for Reading Data\n",
     "\n",
     "Production-scale training data sometimes does not fit into RAM. For this case, CNTK provides the `MinibatchSource` class, which provides:\n",
     "\n",
     " * A **chunked randomization algorithm** that holds only part of the data in RAM at any given time.\n",
     " * **Distributed reading** where each worker reads a different subset.\n",
     " * A **transformation pipeline** for images and image augmentation.\n",
     " * **Composability** across multiple data types (e.g. image captioning).\n",
     " * Transparent **asynchronous loading** so that the GPU is not stalling while a minibatch is read/prepared \n",
     "\n",
     "At present, the `MinibatchSource` class implements a limited set of data types in the form of \"deserializers\":\n",
     "\n",
     " * **Images** (`ImageDeserializer`).\n",
     " * **Speech files** (`HTKFeatureDeserializer`, `HTKMLFDeserializer`).\n",
     " * Data in CNTK's **canonical text format (CTF)**, which consists of a set of named feature channels each containing a one dimensional sparse or dense sequence per example. The CTFDeserializer can then associates each feature channel with an input of your model or criterion.\n",
     "\n",
     "The following example of using the `ImageDeserializer` class shows the general pattern.\n",
     "For the specific input-file formats, please consult the documentation\n",
     "or data-type specific tutorials such as Tutorial 202."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "## 数据的喂养\n",
    "\n",
    "一旦你决定了你的模型结构并定义了它, 你就会面临将你的培训数据 CNTK 培训过程的问题。\n",
    "\n",
    "上面的示例简单地将数据作为 numpy/scipy 数组进行提要。\n",
    "这只是 CNTK 提供给培训者的三种方式之一:\n",
    "\n",
    "1. 作为**numpy 数组**或**scipy 稀疏 (CSR) 矩阵**, 对于只可以加载到 RAM 中的小型数据集。\n",
    "\n",
    "2. 通过**CNTK 的 MinibatchSource 类**的实例, 对于不适合 RAM 的大型数据集。\n",
    "\n",
    "3. 当上述不适用时, 通过**显式 minibatch 循环**。\n",
    "\n",
    "### 1. 通过 Numpy/Scipy 阵列来喂养数据\n",
    "\n",
    "`train()`and `test()` 函数接受 numpy 数组的元组或 scipy 的稀疏矩阵 (以 CSR 格式) 表示其 `minibatch_source` 参数。\n",
    "元组成员的顺序必须与 `criterion` 函数 `train()` 或 `test()` 被调用时的参数相同。\n",
    "对于稠密张量, 请使用 numpy 数组, 而稀疏数据应具有类型 `scipy.sparse.csr_matrix` 。\n",
    "\n",
    "每个参数都应是 numpy/scipy 数组的 Python 列表, 其中每个列表项都表示一个数据项。对于声明为序列的参数, numpy/scipy 数组的第一个轴 (维) 是序列长度, 而其余的坐标轴是序列中每个元素的形状。不是序列的参数由单个张量组成。形状、数据类型 ( `np.float32/float64` ) 和稀疏必须与参数类型匹配。\n",
    "\n",
    "作为一种优化, 不是序列的参数也可以作为单个大的 numpy/scipy 数组 (而不是列表) 传递。这就是上面的例子所做的。\n",
    "\n",
    "请注意, 用户有责任随机化数据。\n",
    "\n",
    "### 2. 使用 \n",
    "\n",
    "生产规模的培训数据有时不适合 RAM。对于这种情况, CNTK 提供了 `MinibatchSource` 类, 它提供了:\n",
    "\n",
    "- 一种**块随机算法**, 它在任何给定时间只保留 RAM 中的一部分数据。\n",
    "\n",
    "- **分布式读取**, 其中每个工作人员读取不同的子集。\n",
    "\n",
    "- 图像和图像增强的**转换管线**。\n",
    "\n",
    "- **组合**跨多个数据类型 (例如, 图像字幕)。\n",
    "\n",
    "- 透明的**异步加载**, 使 GPU 在读取/准备 minibatch 时不会停滞\n",
    "\n",
    "目前, `MinibatchSource` 类以 \"反\" 的形式实现一组有限的数据类型:\n",
    "\n",
    "- **图像**(`ImageDeserializer`).\n",
    "\n",
    "- **语音文件**(`HTKFeatureDeserializer`, `HTKMLFDeserializer`).\n",
    "\n",
    "- CNTK 的**规范文本格式 (周大福)**中的数据, 它由一组命名的特征通道组成, 每个功能频道都包含一个维度的稀疏或密集序列。然后, CTFDeserializer 可以将每个功能通道与您的模型或标准的输入相关联。\n",
    "\n",
    "下面的使用 `ImageDeserializer` 类的示例显示了常规模式。\n",
    "对于特定的输入文件格式, 请查阅文档或数据类型的特定教程, 如教程202。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_width, image_height, num_channels = (32, 32, 3)\n",
    "num_classes = 1000\n",
    "def create_image_reader(map_file, is_training):\n",
    "    transforms = []\n",
    "    if is_training:  # train uses data augmentation (translation only)\n",
    "        transforms += [\n",
    "            cntk.io.transforms.crop(crop_type='randomside', side_ratio=0.8)  # random translation+crop\n",
    "        ]\n",
    "    transforms += [  # to fixed size\n",
    "        cntk.io.transforms.scale(width=image_width, height=image_height, channels=num_channels, interpolations='linear'),\n",
    "    ]\n",
    "    # deserializer\n",
    "    return cntk.io.MinibatchSource(cntk.io.ImageDeserializer(map_file, cntk.io.StreamDefs(\n",
    "        features = cntk.io.StreamDef(field='image', transforms=transforms),\n",
    "        labels   = cntk.io.StreamDef(field='label', shape=num_classes)\n",
    "    )), randomize=is_training, max_sweeps = cntk.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "### 3.  Feeding Data Via an Explicit Minibatch Loop\n",
     "\n",
     "Instead of feeding your data as a whole to CNTK's `train()` and `test()` functions which implement a minibatch loop internally,\n",
     "you can realize your own minibatch loop and call the lower-level APIs `train_minibatch()` and `test_minibatch()`.\n",
     "This is useful when your data is not in a form suitable for the above, such as being generated on the fly as, for example, in variants of reinforcement learning. The `train_minibatch()` and `test_minibatch()` methods require you to instantiate an object of class `Trainer` that takes a subset of the arguments of `train()`. The following implements the logistic-regression example from above through explicit minibatch loops:"
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "### 3. 通过显式 Minibatch 回路给数据喂食\n",
    "\n",
    "您可以实现自己的 minibatch 循环并调用较低级别的 api `train_minibatch()` 和 `test_minibatch()` , 而不是将数据作为一个整体向 CNTK 的 `train()` 和 `test()` 函数 minibatch。\n",
    "当数据的格式不适合上述情况时, 例如在动态生成中, 例如在增强学习的变体中, 这是很有用的。`train_minibatch()`and `test_minibatch()` 方法要求您实例化一个类的对象 `Trainer` , 它采用的是 `train()` 的一个参数子集。下面通过显式 minibatch 循环实现了上述的逻辑回归示例:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate per minibatch: 0.1\n",
      " Minibatch[   1-  50]: loss = 0.663274 * 1600, metric = 37.31% * 1600;\n",
      " Minibatch[  51- 100]: loss = 0.481867 * 1600, metric = 20.56% * 1600;\n",
      " Minibatch[ 101- 150]: loss = 0.402196 * 1600, metric = 12.94% * 1600;\n",
      " Minibatch[ 151- 200]: loss = 0.386619 * 1600, metric = 13.75% * 1600;\n",
      " Minibatch[ 201- 250]: loss = 0.328646 * 1600, metric = 9.19% * 1600;\n",
      " Minibatch[ 251- 300]: loss = 0.301831 * 1600, metric = 9.50% * 1600;\n",
      " Minibatch[ 301- 350]: loss = 0.299345 * 1600, metric = 9.44% * 1600;\n",
      " Minibatch[ 351- 400]: loss = 0.279577 * 1600, metric = 8.94% * 1600;\n",
      " Minibatch[ 401- 450]: loss = 0.281061 * 1600, metric = 8.25% * 1600;\n",
      " Minibatch[ 451- 500]: loss = 0.261366 * 1600, metric = 7.81% * 1600;\n",
      " Minibatch[ 501- 550]: loss = 0.244967 * 1600, metric = 7.12% * 1600;\n",
      " Minibatch[ 551- 600]: loss = 0.243953 * 1600, metric = 8.31% * 1600;\n",
      "Finished Epoch[1]: loss = 0.344399 * 20000, metric = 12.58% * 20000 2.298s (8703.2 samples/s);\n",
      "Finished Evaluation [2]: Minibatch[1-32]: metric = 8.11% * 1024;\n"
     ]
    }
   ],
   "source": [
    "# Recreate the model, so that we can start afresh. This is a direct copy from above.\n",
    "model_lr = cntk.layers.Dense(num_classes_lr, activation=None)\n",
    "@cntk.Function\n",
    "def criterion_lr_factory(data, label_one_hot):\n",
    "    z = model_lr(data)  # apply model. Computes a non-normalized log probability for every output class.\n",
    "    loss = cntk.cross_entropy_with_softmax(z, label_one_hot) # this applies softmax to z under the hood\n",
    "    metric = cntk.classification_error(z, label_one_hot)\n",
    "    return loss, metric\n",
    "\n",
    "x = cntk.input_variable(input_dim_lr)\n",
    "y = cntk.input_variable(num_classes_lr, is_sparse=True)\n",
    "criterion_lr = criterion_lr_factory(x,y)\n",
    "\n",
    "# Create the learner; same as above.\n",
    "learner = cntk.sgd(model_lr.parameters, cntk.learning_parameter_schedule(0.1))\n",
    "\n",
    "# This time we must create a Trainer instance ourselves.\n",
    "trainer = cntk.Trainer(None, criterion_lr, [learner], [cntk.logging.ProgressPrinter(50)])\n",
    "\n",
    "# Train the model by spoon-feeding minibatch by minibatch.\n",
    "minibatch_size = 32\n",
    "for i in range(0, len(X_train_lr), minibatch_size): # loop over minibatches\n",
    "    x = X_train_lr[i:i+minibatch_size] # get one minibatch worth of data\n",
    "    y = Y_train_lr[i:i+minibatch_size]\n",
    "    trainer.train_minibatch({criterion_lr.arguments[0]: x, criterion_lr.arguments[1]: y})  # update model from one minibatch\n",
    "trainer.summarize_training_progress()\n",
    "\n",
    "# Test error rate minibatch by minibatch\n",
    "evaluator = cntk.Evaluator(criterion_lr.outputs[1], [progress_writer]) # metric is the second output of criterion_lr()\n",
    "for i in range(0, len(X_test_lr), minibatch_size): # loop over minibatches\n",
    "    x = X_test_lr[i:i+minibatch_size] # get one minibatch worth of data\n",
    "    y = Y_test_lr[i:i+minibatch_size]\n",
    "    evaluator.test_minibatch({criterion_lr.arguments[0]: x, criterion_lr.arguments[1]: y})  # test one minibatch\n",
    "evaluator.summarize_test_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "## Training and Evaluating\n",
     "\n",
     "In our examples above, we use the `train()` function to train, and `test()` for evaluating.\n",
     "In this section, we want to walk you through the advanced options of `train()`:\n",
     "\n",
     " 1. **Distributed Training** on multiple GPUs using MPI.\n",
     " 2. Callbacks for **Progress Tracking**, **TensorBoard visualization**, **Checkpointing**,**Cross-validation**-based training control, and **Testing** for the final model.\n",
     "\n",
     "### 1. Distributed Training\n",
     "\n",
     "CNTK makes distributed training easy. Out of the box, it supports three methods of distributed training:\n",
     "\n",
     " * Simple **data-parallel** training.\n",
     " * **1-bit SGD**.\n",
     " * **BlockMomentum**.\n",
     "\n",
     "Simple **data-parallel** training distributes each minibatch over N worker processes, where each process utilizes one GPU.\n",
     "After each minibatch, the gradients from all workers are aggregated before updating each model copy.\n",
     "This is often sufficient for convolutional networks, which have a high computation/communication ratio.\n",
     "\n",
     "**1-bit SGD** uses the techniques from [this paper](https://www.microsoft.com/en-us/research/publication/1-bit-stochastic-gradient-descent-and-application-to-data-parallel-distributed-training-of-speech-dnns/) to speed up the communication step in data-parallel training. This method has been found effective for networks where communication cost becomes the dominating factor, such as full-connected networks and some recurrent ones. This method has been found to only minimally degrade accuracy at good speed-ups.\n",
     "\n",
     "**BlockMomentum** uses the techniques from [this paper](https://www.microsoft.com/en-us/research/publication/scalable-training-deep-learning-machines-incremental-block-training-intra-block-parallel-optimization-blockwise-model-update-filtering/) to improvs communication bandwidth by exchanging gradients only every N minibatches.\n",
     "\n",
     "Processes are started with and communicate through MPI. Hence, CNTK's distributed training\n",
     "works both within a single server and across multiple servers.\n",
     "All you need to do is\n",
     "\n",
     " * wrap your learner inside a `distributed_learner` object\n",
     " * execute the Python script using `mpiexec`\n",
     " \n",
     "Unfortunately, MPI cannot be used from a Jupyter notebook. You can find the example below\n",
     "as a standalone Python script under `Examples/1stSteps/MNIST_Complex_Training.py` to run under MPI, for example under MSMPI as\n",
     "\n",
     "`mpiexec -n 4 -lines python -u Examples/1stSteps/MNIST_Complex_Training.py`"
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "## 培训和评估\n",
    "\n",
    "在上面的示例中, 我们使用 `train()` 函数进行训练, 并 `test()` 进行评估。\n",
    "在本节中, 我们要介绍 `train()` 的高级选项:\n",
    "\n",
    "1. 使用 MPI 在多个 gpu 上进行**分布式培训**。\n",
    "\n",
    "2. **None**对**进度跟踪**、 **TensorBoard 可视化**、检查点、基于**验证**的培训控制和**测试**进行最终模型的回调。\n",
    "\n",
    "### 1. 分布式培训\n",
    "\n",
    "CNTK 使分布式培训变得容易。在该框之外, 它支持三种分布式培训方法:\n",
    "\n",
    "- 简单的**数据并行**培训。\n",
    "\n",
    "- **1 位 SGD**。\n",
    "\n",
    "- **BlockMomentum**。\n",
    "\n",
    "简单的**数据并行**培训将每个 minibatch 分布在 N 个工作进程上, 每个进程使用一个 GPU。\n",
    "每次 minibatch 之后, 所有工作人员的渐变都将在更新每个模型副本之前进行聚合。\n",
    "这通常是足够的卷积网络, 有一个高计算/通信比率。\n",
    "\n",
    "**1 位 SGD**使用来自本文的技术来加快数据并行培训中的通信步骤. [None](https://www.microsoft.com/en-us/research/publication/1-bit-stochastic-gradient-descent-and-application-to-data-parallel-distributed-training-of-speech-dnns/)这种方法在通信成本成为控制因素的网络中, 如全连通网络和一些经常性的系统, 已被发现是有效的。这种方法已被发现, 只有在良好的速度 ups 最小降低精度。\n",
    "\n",
    "**BlockMomentum**使用来自本文的技术, 通过仅交换每个 N minibatches 的渐变来 improvs 通信带宽. [None](https://www.microsoft.com/en-us/research/publication/scalable-training-deep-learning-machines-incremental-block-training-intra-block-parallel-optimization-blockwise-model-update-filtering/)\n",
    "\n",
    "进程是通过 MPI 进行的。因此, CNTK 的分布式培训在一台服务器和多台服务器之间运行。\n",
    "你所要做的就是\n",
    "\n",
    "- 在 `distributed_learner` 对象中包装您的学习者\n",
    "\n",
    "- 执行 Python 脚本, 使用`mpiexec`\n",
    "\n",
    "遗憾的是, MPI 不能从 Jupyter 的笔记本中使用。下面的示例可以作为一个独立的 Python 脚本在 `Examples/1stSteps/MNIST_Complex_Training.py` 下运行在 MPI 下, 例如在 MSMPI 下作为\n",
    "\n",
    "`mpiexec -n 4 -lines python -u Examples/1stSteps/MNIST_Complex_Training.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "### 2. Callbacks\n",
     "\n",
     "The `callbacks` parameter of `train()` specifies actions that the `train()` function\n",
     "executes periodically, typically every epoch.\n",
     "The `callbacks` parameter is a list of objects, where the object type decides the specific callback action.\n",
     "\n",
     "Progress trackers allow to log progress (average loss and metric)\n",
     "periodically after N minibatches and after completing each epoch.\n",
     "Optionally, all of the first few minibatches can be logged.\n",
     "The `ProgressPrinter` callback logs to stderr and file, while `TensorBoardProgressWriter`\n",
     "logs events for visualization in TensorBoard.\n",
     "You can also write your own progress tracker class.\n",
     "\n",
     "Next, the `CheckpointConfig` class denotes a callback that writes a checkpoint file every epoch, and automatically restarts training at the latest available checkpoint.\n",
     "\n",
     "The `CrossValidationConfig` class tells CNTK to periodically evaluate the model on a validation data set,\n",
     "and then call a user-specified callback function, which can then update the learning rate of return `False` to indicate early stopping.\n",
     "\n",
     "Lastly, `TestConfig` instructs CNTK to evaluate the model at the end on a given test set.\n",
     "This is the same as the explicit `test()` call in our examples above."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "### 2. 回调\n",
    "\n",
    "`callbacks`参数 `train()` 指定 `train()` 函数定期执行的操作, 通常是每个纪元。\n",
    "`callbacks`参数是对象的列表, 其中对象类型决定特定的回调操作。\n",
    "\n",
    "进度跟踪器允许在 N minibatches 和完成每个纪元后定期记录进度 (平均损耗和度量)。\n",
    "(可选) 可以记录前几个 minibatches。\n",
    "`ProgressPrinter`回调日志到 stderr 和文件, 同时 `TensorBoardProgressWriter` 记录在 TensorBoard 中的可视化事件。\n",
    "您也可以编写自己的进度跟踪器类。\n",
    "\n",
    "接下来, `CheckpointConfig` class 表示一个回调, 每个纪元都写入一个检查点文件, 并在最新的可用检查点上自动重新启动培训。\n",
    "\n",
    "`CrossValidationConfig`类通知 CNTK 定期评估验证数据集上的模型, 然后调用用户指定的回调函数, 然后可以更新返回的学习速率 `False` 以指示早期停止。\n",
    "\n",
    "最后, `TestConfig` 指示 CNTK 在给定测试集的末尾对模型进行评估。\n",
    "这与上面的示例中的显式 `test()` 调用相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "### Putting it all Together: Advanced Training Example\n",
     "\n",
     "Let us now put all of the above examples together into a single training. The following example runs our MNIST example from above with logging, TensorBoard events, checkpointing, CV-based training control, and a final test."
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "### 将其全部放在一起: 高级培训示例\n",
    "\n",
    "现在让我们把以上所有的例子集中到一个单一的训练中。下面的示例从上面运行我们的 MNIST 示例: 日志记录、TensorBoard 事件、检查点、基于 CV 的培训控制以及最终测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redirecting log to file my.log\n",
      "Improvement of metric from 0.011 to 0.011 insufficient. Halving learning rate to 0.0005.\n",
      "Improvement of metric from 0.008 to 0.008 insufficient. Halving learning rate to 0.00025.\n",
      "Improvement of metric from 0.007 to 0.007 insufficient. Halving learning rate to 0.000125.\n",
      "Improvement of metric from 0.007 to 0.007 insufficient. Halving learning rate to 6.25e-05.\n",
      "Improvement of metric from 0.007 to 0.007 insufficient. Halving learning rate to 3.125e-05.\n",
      "Improvement of metric from 0.007 to 0.007 insufficient. Halving learning rate to 1.5625e-05.\n",
      "Learning rate 7.8125e-06 too small. Training complete.\n",
      "loss progression = 0.690, 0.131, 0.091, 0.074, 0.062, 0.054, 0.048, 0.044, 0.040, 0.033, 0.028, 0.027, 0.025, 0.024, 0.023, 0.022, 0.019, 0.020, 0.019, 0.018, 0.018, 0.016, 0.016, 0.016, 0.015, 0.015, 0.014, 0.014, 0.014, 0.014, 0.013, 0.015, 0.014\n"
     ]
    }
   ],
   "source": [
    "# Create model and criterion function.\n",
    "x = cntk.input_variable(input_shape_mn)\n",
    "y = cntk.input_variable(num_classes_mn, is_sparse=True)\n",
    "model_mn = create_model_mn_factory()\n",
    "@cntk.Function\n",
    "def criterion_mn_factory(data, label_one_hot):\n",
    "    z = model_mn(data)\n",
    "    loss = cntk.cross_entropy_with_softmax(z, label_one_hot)\n",
    "    metric = cntk.classification_error(z, label_one_hot)\n",
    "    return loss, metric\n",
    "\n",
    "criterion_mn = criterion_mn_factory(x, y)\n",
    "\n",
    "# Create the learner.\n",
    "learner = cntk.learners.momentum_sgd(model_mn.parameters, lrs, momentums)\n",
    "\n",
    "# Create progress callbacks for logging to file and TensorBoard event log.\n",
    "# Prints statistics for the first 10 minibatches, then for every 50th, to a log file.\n",
    "progress_writer = cntk.logging.ProgressPrinter(50, first=10, log_to_file='my.log')\n",
    "tensorboard_writer = cntk.logging.TensorBoardProgressWriter(50, log_dir='my_tensorboard_logdir',\n",
    "                                                            model=criterion_mn)\n",
    "\n",
    "# Create a checkpoint callback.\n",
    "# Set restore=True to restart from available checkpoints.\n",
    "epoch_size = len(X_train_mn)\n",
    "checkpoint_callback_config = cntk.CheckpointConfig('model_mn.cmf', epoch_size, preserve_all=True, restore=False)\n",
    "\n",
    "# Create a cross-validation based training control.\n",
    "# This callback function halves the learning rate each time the cross-validation metric\n",
    "# improved less than 5% relative, and stops after 6 adjustments.\n",
    "prev_metric = 1 # metric from previous call to the callback. Error=100% at start.\n",
    "def adjust_lr_callback(index, average_error, cv_num_samples, cv_num_minibatches):\n",
    "    global prev_metric\n",
    "    if (prev_metric - average_error) / prev_metric < 0.05: # did metric improve by at least 5% rel?\n",
    "        learner.reset_learning_rate(cntk.learning_parameter_schedule(learner.learning_rate() / 2, minibatch_size=1))\n",
    "        if learner.learning_rate() < lrs[0] / (2**7-0.1): # we are done after the 6-th LR cut\n",
    "            print(\"Learning rate {} too small. Training complete.\".format(learner.learning_rate()))\n",
    "            return False # means we are done\n",
    "        print(\"Improvement of metric from {:.3f} to {:.3f} insufficient. Halving learning rate to {}.\".format(prev_metric, average_error, learner.learning_rate()))\n",
    "    prev_metric = average_error\n",
    "    return True # means continue\n",
    "\n",
    "cv_callback_config = cntk.CrossValidationConfig((X_cv_mn, Y_cv_mn), 3*epoch_size, minibatch_size=256,\n",
    "                                                callback=adjust_lr_callback, criterion=criterion_mn)\n",
    "\n",
    "# Callback for testing the final model.\n",
    "test_callback_config = cntk.TestConfig((X_test_mn, Y_test_mn), criterion=criterion_mn)\n",
    "\n",
    "# Train!\n",
    "callbacks = [progress_writer, tensorboard_writer, checkpoint_callback_config, cv_callback_config, test_callback_config]\n",
    "progress = criterion_mn.train((X_train_mn, Y_train_mn), minibatch_size=minibatch_sizes,\n",
    "                              max_epochs=50, parameter_learners=[learner], callbacks=callbacks)\n",
    "\n",
    "# Progress is available from return value\n",
    "losses = [summ.loss for summ in progress.epoch_summaries]\n",
    "print('loss progression =', \", \".join([\"{:.3f}\".format(loss) for loss in losses]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "## Deploying your Model\n",
     "\n",
     "Your ultimate purpose of training a deep neural network is to deploy it as part of your own program or product.\n",
     "Since this involves programming languages other than Python,\n",
     "we will only give a high-level overview here, and refer you to specific examples.\n",
     "\n",
     "Once you completed training your model, it can be deployed in a number of ways.\n",
     "\n",
     " * Directly in your **Python** program.\n",
     " * From any other language that CNTK supports, including **C++**, **C#**, and **Java**.\n",
     " * From **your own web service**.\n",
     " * Through a web service deployed to **Microsoft Azure**.\n",
     "\n",
     "The first step in all cases is to make sure your model's input types are known (you can just print the model and inspect the inputs), and then to save your model to disk after training:"
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "## 部署模型\n",
    "\n",
    "训练深层神经网络的终极目的是将其部署为您自己的程序或产品的一部分。\n",
    "因为这涉及到编程语言, 而不是 Python, 我们将只在这里给出一个高层次的概述, 并参考您的具体例子。\n",
    "\n",
    "一旦您完成了对模型的培训, 就可以通过多种方式进行部署。\n",
    "\n",
    "- 直接在您的**Python**程序中。\n",
    "\n",
    "- 来自 CNTK 支持的任何其他语言, 包括 c++、 **None** **c#**和**Java**。\n",
    "\n",
    "- 从**您自己的 web 服务**。\n",
    "\n",
    "- 通过部署到**Microsoft Azure**的 web 服务。\n",
    "\n",
    "在所有情况下, 第一步是确保您的模型的输入类型是已知的 (您可以只打印模型并检查输入), 然后在培训后将模型保存到磁盘:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composite(keep: Sequence[tensor]) -> Sequence[tensor]\n",
      "Composite(Tensor[28,28]) -> Tensor[10]\n"
     ]
    }
   ],
   "source": [
    "print(model_mn)\n",
    "x = cntk.input_variable(input_shape_mn)\n",
    "model = model_mn(x)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('mnist.cmf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "Deploying your model in a Python-based program is easy: Since networks are function objects that are callable, like a function, simply load the model, and call it with inputs, as we have already shown above:"
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "在基于 Python 的程序中部署模型很简单: 因为网络是可调用的函数对象, 就像函数一样, 只需加载模型, 然后用输入调用它, 正如我们上面已经显示的:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized as: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEEAAAA+CAYAAAB0g3ZRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAAspJREFUaIHt2btLK0EUx/HvDmIVsRCDomCphSjG\nRgvB9K6IaJc6YKFirwZtrK3i32CrphYsgiAoKBaptPKBEVFWkC1+t7i4EF8k3mtuknsObDHM7jw+\nezLMTjxJ/O/h/vUAaiEMAUMADAEwBMAQAEMADAEwBMAQAGiqcn/V3qN75dxkmYAhAIYA1DDC09MT\n+Xyei4sLXl5eODs7+7nOJFXzKjsWFxflnFNXV5cSiYRaW1u1vLxcSRMqd1w1ibC2tqZYLCbnnJxz\n8jxPzjnFYjHt7Ow0NkIQBMpkMgLkeV50tbS0lJQbGmFzc7PkzcfjcS0sLOjk5EQzMzNRZlSQDfWH\nMDo6GiHMzs6qUChEdY+PjxoYGJBzTnNzc42LcHBwoGQyqUwmo+fn50+RpqamGhfhq9jY2IjWhFQq\nVe5jZY2r2t8O347j42M87/enwMrKyt9t/Iff/LcyIQgCbW9v6+7uTpJ0fX2t9vb2aGGsIOorE3Z3\nd8nlcuzt7RGGITc3N8TjcUZGRjg8PKRYLAKQzWbfPbu+vk4ulwPg6uqKy8vLyjqvhUw4Pz8v2Qfw\nZp/wWvZ9X2EYKgxDZbNZLS0taXx8PKrv6Oh4u2jWz8LY29sbpXp3d7fm5+c1ODj4bsfonJPv+5qY\nmIjKr/XJZDL6+dQlwuske3p6dHp6qiAIND09/SHC23JfX5/y+fxHAPWJMDQ0pFQqpc7OzpJJp9Pp\ndwiTk5Pa2trSw8PDZ83WF8Lq6uqHa8DY2Jj29/dL7j06Ovpq0t9C8KSqHvt92Nnt7S39/f0Ui0WG\nh4dpamrC933S6TRtbW1/0l9ZZ4w1gQBQKBS4v78nkUjQ3Nz8t/qrL4QfCjttLjcMAUMADAGo/t9w\nZS1U1Q7LBAwBMATAEABDAAwBMATAEABDAAwBMATAEABDAAwBMATAEABDAAwBMATAEABDAAwBMAQA\nfgF2BE6Yr22L9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1721a8332b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# At program start, load the model.\n",
    "classify_digit = cntk.Function.load('mnist.cmf')\n",
    "\n",
    "# To apply model, just call it.\n",
    "image_input = X_test_mn[8345]        # (pick a random test digit for illustration)\n",
    "scores = classify_digit(image_input) # call the model function with the input data\n",
    "image_class = scores.argmax()        # find the highest-scoring class\n",
    "\n",
    "# And that's it. Let's have a peek at the result\n",
    "print('Recognized as:', image_class)\n",
    "matplotlib.pyplot.axis('off')\n",
    "_ = matplotlib.pyplot.imshow(image_input, cmap=\"gray_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "Models can be deployed directly from programs written in other programming languages for which bindings exist.\n",
     "Please see the following example programs for an example similar to the Python one above:\n",
     "\n",
     " * C++: `Examples/Evaluation/CNTKLibraryCPPEvalCPUOnlyExamples/CNTKLibraryCPPEvalCPUOnlyExamples.cpp`\n",
     " * C#: `Examples/Evaluation/CNTKLibraryCSEvalCPUOnlyExamples/CNTKLibraryCSEvalExamples.cs`\n",
     "\n",
     "To deploy a model from your own web service, load and invoke the model in the same way.\n",
     "\n",
     "To deploy a model via an Azure web service, follow this tutorial: `Examples/Evaluation/CNTKAzureTutorial01`"
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "模型可以直接部署到用其他编程语言编写的程序中, 而绑定存在。\n",
    "请参见下面的示例程序, 类似于上面的 Python 示例:\n",
    "\n",
    "- c++:`Examples/Evaluation/CNTKLibraryCPPEvalCPUOnlyExamples/CNTKLibraryCPPEvalCPUOnlyExamples.cpp`\n",
    "\n",
    "- c#:`Examples/Evaluation/CNTKLibraryCSEvalCPUOnlyExamples/CNTKLibraryCSEvalExamples.cs`\n",
    "\n",
    "要从您自己的 web 服务部署模型, 请以相同的方式加载和调用模型。\n",
    "\n",
    "要通过 Azure web 服务部署模型, 请按照以下教程操作:`Examples/Evaluation/CNTKAzureTutorial01`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "original_source": [
     "## Conclusion\n",
     "\n",
     "This tutorial provided an overview of the five main tasks of creating and using a deep neural network with CNTK.\n",
     "\n",
     "We first examined CNTK's Functional programming and its tensor/sequence-based data model.\n",
     "Then we considered the possible ways of feeding data to CNTK, including directly from RAM,\n",
     "through CNTK's data-reading infrastructure (`MinibatchSource`), and spoon-feeding through a custom minibatch loop.\n",
     "We then took a look at CNTK's advanced training options, including distributed training, logging to TensorBoard, checkpointing, CV-based training control, and final model evaluation.\n",
     "Lastly, we briefly looked into model deployment.\n",
     "\n",
     "We hope this guided your have you a good starting point for your own ventures with CNTK. Please enjoy!"
    ]
   },
   "source": [
    "_unchecked_\n",
    "\n",
    "## 结论\n",
    "\n",
    "本教程概述了创建和使用具有 CNTK 的深层神经网络的五主要任务。\n",
    "\n",
    "我们首先研究了 CNTK 的函数规划及其基于张量/序列的数据模型。\n",
    "然后, 我们考虑了通过 CNTK 的数据读取基础结构 ( `MinibatchSource` ) 和通过自定义 minibatch 循环进行的填鸭式的 CNTK, 将数据直接从 RAM 中送进的可能方法。\n",
    "然后, 我们看了 CNTK 的高级培训选项, 包括分布式培训、日志记录到 TensorBoard、检查点、基于 CV 的培训控制和最终模型评估。\n",
    "最后, 我们简要地研究了模型部署。\n",
    "\n",
    "我们希望这引导您有您有一个好起点为您自己的事业与 CNTK。请尽情享受!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}